# -*- coding: utf-8 -*-
"""MB-WNN-CNN (4 subbands).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://drive.google.com/file/d/1IqAcj7_NwIOMkDOps3VNIGOxhYBOgDrH/view?usp=sharing

# **MB-WNN-CNN-extend**: A novel multi-branch wavelet neural network for sparse representation based object classification (MB-WNN-CNN) is a transductive classification model based on sparse representations. 

#Author:  **Tan-Sy NGUYEN**

Connect the **Google Colab** with **Google Drive**
"""

import torch
import numpy as np

from torchvision import datasets
from torch.utils.data import DataLoader
from torch.utils.data.dataset import Dataset
import os
import torch.nn as nn
import torch.nn.functional as F
import scipy.io as io
import math
from PIL import Image
from collections import OrderedDict
from pytorch_wavelets import DWTForward, DWTInverse  # (or import DWT, IDWT)
from loss_fn import loss_fn
from checkPoint import ImproveChecker
from Evaluate import Evaluate

"""## 1. Define the **Loss function** including 3 main parts:

1.   Reconstruction Loss between the original image and reconstructed image
2.   Expression Loss based on the SRC equation
3.   Regular Loss: L1 loss of sparse code
"""


class VAEGT(nn.Module):
    def __init__(self, split_ratio, batch_size=1000, num_classes=10, negative_slope=0.1, imageshape=32):
        super(VAEGT, self).__init__()
        self.batch_size = batch_size
        self.split_ratio = split_ratio
        self.emb_outshape = math.ceil(imageshape) / 8

        self.train_size = int(self.split_ratio * self.batch_size)
        self.test_size = batch_size - self.train_size

        self.num_classes = num_classes
        self.negative_slope = negative_slope

        # Encoder declaration
        self.encoderLL = nn.Sequential(OrderedDict([
            ('layer1', nn.Conv2d(in_channels=1, out_channels=8, kernel_size=5, stride=2, padding=(2, 2))),
            ('relu1', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
            ('layer2', nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=2, padding=(1, 1))),
            ('relu2', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
            ('layer3', nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=(1, 1))),
            ('relu3', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
            ('layer4', nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=(1, 1))),
            ('relu4', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
        ]))

        self.encoderLH = nn.Sequential(OrderedDict([
            ('layer1', nn.Conv2d(in_channels=1, out_channels=8, kernel_size=5, stride=2, padding=(2, 2))),
            ('relu1', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
            ('layer2', nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=2, padding=(1, 1))),
            ('relu2', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
            ('layer3', nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=(1, 1))),
            ('relu3', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
            ('layer4', nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=(1, 1))),
            ('relu4', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
        ]))

        self.encoderHL = nn.Sequential(OrderedDict([
            ('layer1', nn.Conv2d(in_channels=1, out_channels=8, kernel_size=5, stride=2, padding=(2, 2))),
            ('relu1', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
            ('layer2', nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=2, padding=(1, 1))),
            ('relu2', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
            ('layer3', nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=(1, 1))),
            ('relu3', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
            ('layer4', nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=(1, 1))),
            ('relu4', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
        ]))

        self.encoderHH = nn.Sequential(OrderedDict([
            ('layer1', nn.Conv2d(in_channels=1, out_channels=8, kernel_size=5, stride=2, padding=(2, 2))),
            ('relu1', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
            ('layer2', nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=2, padding=(1, 1))),
            ('relu2', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
            ('layer3', nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=(1, 1))),
            ('relu3', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
            ('layer4', nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=(1, 1))),
            ('relu4', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
        ]))

        # Sparse layer declaration
        self.sparsecodeLL = torch.nn.Parameter(1.0e-4 * torch.ones(self.test_size, self.train_size).cuda(),
                                               requires_grad=True)
        self.sparsecodeLH = torch.nn.Parameter(1.0e-4 * torch.ones(self.test_size, self.train_size).cuda(),
                                               requires_grad=True)
        self.sparsecodeHL = torch.nn.Parameter(1.0e-4 * torch.ones(self.test_size, self.train_size).cuda(),
                                               requires_grad=True)
        self.sparsecodeHH = torch.nn.Parameter(1.0e-4 * torch.ones(self.test_size, self.train_size).cuda(),
                                               requires_grad=True)
        # self._reshape = nn.Sequential(OrderedDict([
        #     ('reshape', nn.Linear(896, 512)),
        # ]))

        # Decoder declaration
        self.decoderLL = nn.Sequential(OrderedDict([
            ('layer1', nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=(1, 1))),
            ('relu1', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
            ('layer2', nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=3, stride=2, padding=(1, 1))),
            ('relu2', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
            ('layer3', nn.ConvTranspose2d(in_channels=8, out_channels=1, kernel_size=5, stride=2, padding=(1, 1),
                                          output_padding=[1, 1])),
            ('relu3', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
        ]))

        self.decoderLH = nn.Sequential(OrderedDict([
            ('layer1', nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=(1, 1))),
            ('relu1', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
            ('layer2', nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=3, stride=2, padding=(1, 1))),
            ('relu2', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
            ('layer3', nn.ConvTranspose2d(in_channels=8, out_channels=1, kernel_size=5, stride=2, padding=(1, 1),
                                           output_padding=[1, 1])),
            ('relu3', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
        ]))

        self.decoderHL = nn.Sequential(OrderedDict([
            ('layer1', nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=(1, 1))),
            ('relu1', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
            ('layer2', nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=3, stride=2, padding=(1, 1))),
            ('relu2', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
            ('layer3', nn.ConvTranspose2d(in_channels=8, out_channels=1, kernel_size=5, stride=2, padding=(1, 1),
                                          output_padding=[1, 1])),
            ('relu3', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
        ]))

        self.decoderHH = nn.Sequential(OrderedDict([
            ('layer1', nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=(1, 1))),
            ('relu1', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
            ('layer2', nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=3, stride=2, padding=(1, 1))),
            ('relu2', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
            ('layer3', nn.ConvTranspose2d(in_channels=8, out_channels=1, kernel_size=5, stride=2, padding=(1, 1),
                                         output_padding=[1, 1])),
            ('relu3', nn.LeakyReLU(negative_slope=negative_slope, inplace=True)),
        ]))

        self._init_weights()

    def forward(self, x_train_LL, x_train_LH, x_train_HL, x_train_HH, y_train, x_test_LL, x_test_LH, x_test_HL, x_test_HH, y_test):
        if self.training:
            # Encode input
            # i = torch.cat([imgs_train, imgs_test], dim =0).cuda()
            x_LL = torch.cat([x_train_LL, x_test_LL], dim=0).cuda()
            x_LH = torch.cat([x_train_LH, x_test_LH], dim=0).cuda()
            x_HL = torch.cat([x_train_HL, x_test_HL], dim=0).cuda()
            x_HH = torch.cat([x_train_HH, x_test_HH], dim=0).cuda()

            z_train_LL = self.encoderLL(x_train_LL.cuda())
            z_train_LH = self.encoderLH(x_train_LH.cuda())
            z_train_HL = self.encoderHL(x_train_HL.cuda())
            z_train_HH = self.encoderHH(x_train_HH.cuda())

            z_train_LL = torch.reshape(z_train_LL, [self.train_size, -1])
            z_train_LH = torch.reshape(z_train_LH, [self.train_size, -1])
            z_train_HL = torch.reshape(z_train_HL, [self.train_size, -1])
            z_train_HH = torch.reshape(z_train_HH, [self.train_size, -1])

            z_test_LL = self.encoderLL(x_test_LL.cuda())
            z_test_LH = self.encoderLH(x_test_LH.cuda())
            z_test_HL = self.encoderHL(x_test_HL.cuda())
            z_test_HH = self.encoderHH(x_test_HH.cuda())

            z_test_LL_o = torch.reshape(z_test_LL, [self.test_size, -1])
            z_test_LH_o = torch.reshape(z_test_LH, [self.test_size, -1])
            z_test_HL_o = torch.reshape(z_test_HL, [self.test_size, -1])
            z_test_HH_o = torch.reshape(z_test_HH, [self.test_size, -1])

            z_LL = torch.cat([z_train_LL, z_test_LL_o], dim=0)
            z_LH = torch.cat([z_train_LH, z_test_LH_o], dim=0)
            z_HL = torch.cat([z_train_HL, z_test_HL_o], dim=0)
            z_HH = torch.cat([z_train_HH, z_test_HH_o], dim=0)

            # Sparse coding
            z_test_LL_c = torch.matmul(self.sparsecodeLL, z_train_LL)
            z_test_LH_c = torch.matmul(self.sparsecodeLH, z_train_LH)
            z_test_HL_c = torch.matmul(self.sparsecodeHL, z_train_HL)
            z_test_HH_c = torch.matmul(self.sparsecodeHH, z_train_HH)

            # Encode label
            y_train_onehot = self._onehot(y_train)
            y_test_onehot = self._onehot(y_test)

            z_LL_c = torch.cat([z_train_LL, z_test_LL_c], dim=0)
            z_LH_c = torch.cat([z_train_LH, z_test_LH_c], dim=0)
            z_HL_c = torch.cat([z_train_HL, z_test_HL_c], dim=0)
            z_HH_c = torch.cat([z_train_HH, z_test_HH_c], dim=0)

            z_LL_c_o = torch.reshape(z_LL_c, [self.batch_size, z_test_LL.shape[1], z_test_LL.shape[2], z_test_LL.shape[3]])
            z_LH_c_o = torch.reshape(z_LH_c, [self.batch_size, z_test_LL.shape[1], z_test_LL.shape[2], z_test_LL.shape[3]])
            z_HL_c_o = torch.reshape(z_HL_c, [self.batch_size, z_test_LL.shape[1], z_test_LL.shape[2], z_test_LL.shape[3]])
            z_HH_c_o = torch.reshape(z_HH_c, [self.batch_size, z_test_LL.shape[1], z_test_LL.shape[2], z_test_LL.shape[3]])

            # Decode
            x_LL_c = self.decoderLL(z_LL_c_o)
            x_LH_c = self.decoderLH(z_LH_c_o)
            x_HL_c = self.decoderHL(z_HL_c_o)
            x_HH_c = self.decoderHH(z_HH_c_o)


            return self.sparsecodeLL, z_LL, z_LL_c, x_LL, x_LL_c, self.sparsecodeLH, z_LH, z_LH_c, x_LH, x_LH_c, self.sparsecodeHL, z_HL, z_HL_c, x_HL, x_HL_c, self.sparsecodeHH, z_HH, z_HH_c, x_HH, x_HH_c

    def _onehot(self, y):
        y_onehot = torch.FloatTensor(y.shape[0], self.num_classes)
        y_onehot.zero_()
        y_onehot.scatter_(1, y.long(), 1)
        return y_onehot

    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                m.weight.data.normal_(0, 0.01)
                m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()



def main():
    # check if CUDA is available
    train_on_gpu = torch.cuda.is_available()

    if not train_on_gpu:
        print('CUDA is not available.  Training on CPU ...')
    else:
        print('CUDA is available!  Training on GPU ...')

    num_epoch = 10000  # number of training epoch
    cal_epoch = 100  # the epoch in which we calculate the accuracy
    mat_path = ('YaleB_192x168.mat')
    split_ratio = 0.9
    num_classes = 40
    size = [192, 168]  # size of input image
    _use_data = [False, False, True]

    print("===> Use default dataset from .mat file \n [path]: %s" % (mat_path))
    custom_data = MyDataset(mat_path, split_ratio=split_ratio, width=size[0], height=size[1])
    data_train, data_test = custom_data._generate()

    dataloader_train = torch.utils.data.DataLoader(dataset=data_train,
                                                   num_workers=4,
                                                   batch_size=1800,
                                                   pin_memory=True)

    dataloader_test = torch.utils.data.DataLoader(dataset=data_test,
                                                  num_workers=4,
                                                  batch_size=200,
                                                  pin_memory=True)
    if dataloader_train.dataset:
        print("\n Dataset change: Load CUSTOM data from .mat file successfully .... \n", dataloader_train.dataset)
        print("\n Training set: %d samples, Testing set: %d samples " % (
        len(dataloader_train.dataset), len(dataloader_test.dataset)))

    # Prepare input

    for i, (inputs_train_LL, inputs_train_LH, inputs_train_HL, inputs_train_HH, labels_train) in enumerate(
            dataloader_train):  # Dataloader for training set
        labels_train = labels_train.view(-1, 1)
        y_onehot_train = torch.FloatTensor(inputs_train_LL.shape[0], num_classes)
        y_onehot_train.zero_()
        y_onehot_train.scatter_(1, labels_train, 1).cuda()

    for j, (inputs_test_LL, inputs_test_LH, inputs_test_HL, inputs_test_HH, labels_test) in enumerate(
            dataloader_test):  # Dataloader for testing set
        labels_test = labels_test.view(-1, 1)
        y_onehot_test = torch.FloatTensor(inputs_test_LL.shape[0], num_classes)
        y_onehot_test.zero_()
        y_onehot_test.scatter_(1, labels_test, 1).cuda()

    model = VAEGT(split_ratio=split_ratio, batch_size=custom_data.__len__(), num_classes=50,
                  imageshape=inputs_train_LL.shape[2])
    model.cuda()

    # Optimizers
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)

    # ImproveChecker
    improvechecker = ImproveChecker(mode='min')

    model.train()
    xim = DWTInverse(wave='haar').cuda()
    for epoch in range(1, num_epoch):
        # Training
        optimizer.zero_grad()
        sparsecodeLL, z_LL, z_LL_c, x_LL, x_LL_c, sparsecodeLH, z_LH, z_LH_c, x_LH, x_LH_c, sparsecodeHL, z_HL, z_HL_c, x_HL, x_HL_c, sparsecodeHH, z_HH, z_HH_c, x_HH, x_HH_c = model(
            inputs_train_LL, inputs_train_LH, inputs_train_HL, inputs_train_HH, y_onehot_train, inputs_test_LL,
            inputs_test_LH, inputs_test_HL, inputs_test_HH, y_onehot_test)
        loss = loss_fn(sparsecodeLL, z_LL, z_LL_c, x_LL, x_LL_c, sparsecodeLH, z_LH, z_LH_c, x_LH, x_LH_c, sparsecodeHL,
                       z_HL, z_HL_c, x_HL, x_HL_c, sparsecodeHH, z_HH, z_HH_c, x_HH, x_HH_c)
        loss.backward()
        optimizer.step()

        print("\n[EPOCH %.3d] Loss: %.6f" % (epoch, loss.item()))
        if (epoch % cal_epoch == 0):
            # ImproveChecker (check the best result)
            accuracy,accuracy2,accuracy3 = Evaluate(coefLL=model.sparsecodeLL, coefLH=model.sparsecodeLH, coefHL=model.sparsecodeHL,
                                coefHH=model.sparsecodeHH, train_labels=labels_train, test_labels=labels_test)._eval()
            print("=================>_Accuracy: %.6f" % (accuracy))
            print("=================>_Accuracy2: %.6f" % (accuracy2))
            print("=================>_Accuracy2: %.6f" % (accuracy3))

            # Save checkpoint
            if improvechecker._check(loss.item()):
                checkpoint = dict(
                    epoch=epoch,
                    loss=loss.item(),
                    state_dict=model.state_dict(),
                    optimizer=optimizer.state_dict(),
                )
                # save_file = os.path.join('CAE.pth')
                torch.save(checkpoint, "CAE.pth")





"""## 2. Define the **model**"""
if __name__ == '__main__':
    main()

"""## 8. Training process"""

# Training process
